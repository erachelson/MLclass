{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is part of the [Machine Learning class](https://github.com/erachelson/MLclass) by [Emmanuel Rachelson](https://personnel.isae-supaero.fr/emmanuel-rachelson?lang=en).\n",
    "\n",
    "License: CC-BY-SA-NC."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"font-size:22pt; line-height:25pt; font-weight:bold; text-align:center;\">Random Forests</div>\n",
    "\n",
    "1. [Random Forests](#sec1)\n",
    "2. [Examples](#sec2)\n",
    "    1. [Spam or ham?](#sec2-1)\n",
    "    2. [NIST](#sec2-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id=\"sec1\"></a> 1. Random Forests\n",
    "\n",
    "Key idea: Grow a forest of trees by introducing randomness.\n",
    "\n",
    "Randomness in:\n",
    "-  Training subset selection (Bagging)\n",
    "- Feature selection in each node\n",
    "\n",
    "**Reminder: growing trees**\n",
    "\n",
    "**FormTree($T$)**<br>\n",
    "<ol>\n",
    "<li> Find best split $(j, s)$ over $T$ // Which criterion?\n",
    "<li> If $(j, s) = \\emptyset$, \n",
    "    <ul>\n",
    "    <li>  node = FormLeaf(T) // Which value for the leaf?\n",
    "    </ul>\n",
    "<li> Else\n",
    "    <ul>\n",
    "    <li> node = $(j, s)$\n",
    "    <li> split $T$ according to $(j, s)$ into $(T1, T2)$\n",
    "    <li> append FormTree($T1$) to node // Recursive call\n",
    "    <li> append FormTree($T2$) to node\n",
    "    </ul>\n",
    "<li> Return node\n",
    "</ol>\n",
    "\n",
    "**New: random feature selection**\n",
    "\n",
    "During step 1 (splitting) of FormTree(T), only search for the best split among a random subset of features.\n",
    "\n",
    "Size of the subset has little importance. Usual choices:\n",
    "- $\\sqrt{p}$ in common cases\n",
    "- 1 for fully randomized feature selection (still gives accurate results!)\n",
    "\n",
    "**Reminder: Forest growth by Bagging of trees**\n",
    "\n",
    "Example Set $T$, samples $x^1,\\ldots, x^N$.<br>\n",
    "For $b=1$ to $B$\n",
    "1. Sample (with replacement) bootstrap replicate $T^b$ from $T$\n",
    "2. $\\varphi^b(x) \\leftarrow$ FormTree($T^b$)\n",
    "\n",
    "Return $\\varphi_B(x) = \\arg\\max\\limits_{y} \\sum\\limits_{b=1}^B I(\\varphi^b(x) = y)$\n",
    "\n",
    "<div class=\"alert alert-success\">\n",
    "    \n",
    "**Random Forests**\n",
    "<ul>\n",
    "<li> Fully grown trees\n",
    "<li> + Random feature selection\n",
    "<li> + Bagging\n",
    "</ul>\n",
    "</div>\n",
    "\n",
    "**Margin guarantees?**\n",
    "\n",
    "Margin of a random forest in $(x,y)$ = \n",
    "probability of classifying correctly $x$, minus probability of the most probable wrong class.<br>\n",
    "$$m(x,y) = \\mathbb{P}_\\Theta\\left(h\\left(x,\\Theta\\right)=y\\right) - \\max\\limits_{j\\neq y}\\mathbb{P}_\\Theta\\left(h\\left(x,\\Theta\\right)=j\\right)$$\n",
    "As more trees are added, Random Forests converge to a bound in generalization error and do not overfit the training set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "def gen_data(seed):\n",
    "    X1, y1 = datasets.make_gaussian_quantiles(cov=2.,\n",
    "                                 n_samples=300, n_features=2,\n",
    "                                 n_classes=2, random_state=seed)\n",
    "    X2, y2 = datasets.make_gaussian_quantiles(mean=(3, 3), cov=1.5,\n",
    "                                 n_samples=700, n_features=2,\n",
    "                                 n_classes=2, random_state=seed)\n",
    "    X = np.concatenate((X1, X2))\n",
    "    y = np.concatenate((y1, - y2 + 1))\n",
    "    y = 2*y-1\n",
    "    X, y = shuffle(X, y)\n",
    "    return X, y\n",
    "\n",
    "X,y = gen_data(1)\n",
    "Xtest,X = np.split(X,[400])\n",
    "ytest,y = np.split(y,[400])\n",
    "\n",
    "Xblue = X[y==-1]\n",
    "Xred = X[y==1]\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.scatter(Xblue[:,0],Xblue[:,1],c='b')\n",
    "plt.scatter(Xred[:,0],Xred[:,1],c='r');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "### Generate data\n",
    "X,y = gen_data(1)\n",
    "Xtest,X = np.split(X,[400])\n",
    "ytest,y = np.split(y,[400])\n",
    "\n",
    "def plot_decision_boundary(f,X,y):\n",
    "    plot_step = 0.02\n",
    "    x0_min, x0_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "    x1_min, x1_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "    xx0, xx1 = np.meshgrid(np.arange(x0_min, x0_max, plot_step), np.arange(x1_min, x1_max, plot_step))\n",
    "    yypred = f.predict(np.c_[xx0.ravel(),xx1.ravel()])\n",
    "    yypred = yypred.reshape(xx0.shape)\n",
    "    plt.figure()\n",
    "    plt.contourf(xx0, xx1, yypred, cmap=plt.cm.Paired)\n",
    "    y_pred = f.predict(X)\n",
    "    Xblue_good = X[np.equal(y,-1)*np.equal(y,y_pred)]\n",
    "    Xblue_bad  = X[np.equal(y,-1)*np.not_equal(y,y_pred)]\n",
    "    Xred_good  = X[np.equal(y,1)*np.equal(y,y_pred)]\n",
    "    Xred_bad   = X[np.equal(y,1)*np.not_equal(y,y_pred)]\n",
    "    plt.scatter(Xblue_good[:,0],Xblue_good[:,1],c='b')\n",
    "    plt.scatter(Xblue_bad[:,0],Xblue_bad[:,1],c='c',marker='v')\n",
    "    plt.scatter(Xred_good[:,0],Xred_good[:,1],c='r')\n",
    "    plt.scatter(Xred_bad[:,0],Xred_bad[:,1],c='m',marker='v')\n",
    "    plt.show()\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=101, criterion='entropy')\n",
    "rf.fit(X,y)\n",
    "\n",
    "# Plot\n",
    "print(\"Generalization error: %g\"%(1.-rf.score(Xtest,ytest)))\n",
    "plt.figure(figsize=(8,8))\n",
    "plot_decision_boundary(rf,X,y)\n",
    "\n",
    "# Feature importance\n",
    "importances = rf.feature_importances_\n",
    "std = np.std([tree.feature_importances_ for tree in rf.estimators_], axis=0)\n",
    "indices = np.argsort(importances)[::-1]\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.title(\"Feature importances\")\n",
    "plt.bar(range(X.shape[1]), importances[indices], color=\"r\", yerr=std[indices], align=\"center\")\n",
    "plt.xticks(range(X.shape[1]), indices)\n",
    "plt.xlim([-1, X.shape[1]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forests provide an interesting **feature importance** estimation mechanism. Let's illustrate it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A more demonstrative example\n",
    "# Build a classification task using 10 features but only 3 informative ones.\n",
    "X, y = datasets.make_classification(n_samples=1000,\n",
    "                                    n_features=10,\n",
    "                                    n_informative=3,\n",
    "                                    n_redundant=0,\n",
    "                                    n_repeated=0,\n",
    "                                    n_classes=2,\n",
    "                                    random_state=0,\n",
    "                                    shuffle=False)\n",
    "rf = RandomForestClassifier(n_estimators=51, criterion='entropy')\n",
    "rf.fit(X,y)\n",
    "importances = rf.feature_importances_\n",
    "std = np.std([tree.feature_importances_ for tree in rf.estimators_], axis=0)\n",
    "indices = np.argsort(importances)[::-1]\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.title(\"Feature importances\")\n",
    "plt.bar(range(X.shape[1]), importances[indices], color=\"r\", yerr=std[indices], align=\"center\")\n",
    "plt.xticks(range(X.shape[1]), indices)\n",
    "plt.xlim([-1, X.shape[1]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id=\"sec4\"></a> 4. Examples\n",
    "\n",
    "## <a id=\"sec4-1\"></a> 4.1 Spam or ham?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sys import path\n",
    "path.append('../2 - Text data preprocessing')\n",
    "import load_spam\n",
    "spam_data = load_spam.spam_data_loader()\n",
    "spam_data.load_data()\n",
    "print(\"data loaded\")\n",
    "\n",
    "Xtrain, ytrain, Xtest, ytest = spam_data.split(2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    \n",
    "**Exercice:** train a Random Forest on this tf-idf data and evaluate its generalization performance.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/code1.py\n",
    "### WRITE YOUR CODE HERE\n",
    "# If you get stuck, uncomment the line above to load a correction in this cell (then you can execute this code).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    \n",
    "**Exercice:** Evaluate how the same Random Forest trained on raw word counts performs.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain, ytrain, Xtest, ytest = spam_data.split(2000, feat='wordcount')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/code2.py\n",
    "### WRITE YOUR CODE HERE\n",
    "# If you get stuck, uncomment the line above to load a correction in this cell (then you can execute this code).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's keep this last classifier and identify which are the misclassified emails."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrain\n",
    "Xtrain, ytrain, Xtest, ytest = spam_data.split(2000, feat=\"wordcount\")\n",
    "spam_RF = RandomForestClassifier(n_estimators=200, criterion='entropy')\n",
    "spam_RF.fit(Xtrain,ytrain);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find misclassified examples\n",
    "ypredict = spam_RF.predict(Xtest)\n",
    "misclass = np.not_equal(ypredict, ytest)\n",
    "Xmisclass = Xtest[misclass,:]\n",
    "ymisclass = ytest[misclass]\n",
    "misclass_indices = [i for i, j in enumerate(misclass) if j == True]\n",
    "print(\"Misclassified messages indices:\", misclass_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "print(\"Confusion matrix:\")\n",
    "print(confusion_matrix(ytest, ypredict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check some misclassified mails\n",
    "index = misclass_indices[0]+2000\n",
    "print(\"Prediction:\", spam_RF.predict(spam_data.word_count[index,:]))\n",
    "spam_data.print_email(index)\n",
    "spam_RF.predict_proba(spam_data.word_count[index,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember there are 14279 features. Let's plot the histogram of feature importances for the 100 most important ones (and their standard deviation).\n",
    "\n",
    "Let's also print the 20 most important words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = spam_RF.feature_importances_\n",
    "std = np.std([tree.feature_importances_ for tree in spam_RF.estimators_], axis=0)\n",
    "indices = np.argsort(importances)[::-1]\n",
    "indices100 = indices[0:100]\n",
    "fig=plt.figure(figsize=(10,10), dpi= 80, facecolor='w', edgecolor='k')\n",
    "plt.title(\"Feature importances\")\n",
    "plt.bar(range(indices100.shape[0]), importances[indices100], color=\"r\", yerr=std[indices100], align=\"center\")\n",
    "plt.xticks(range(indices100.shape[0]), indices100)\n",
    "plt.xlim([-1, indices100.shape[0]])\n",
    "plt.show()\n",
    "print(\"Most important words:\")\n",
    "for i in range(20):\n",
    "    print(spam_data.feat2word[indices100[i]],end=\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Â 4.2 <a id=\"sec4-1\"></a> NIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "digits = datasets.load_digits()\n",
    "print(digits.data.shape)\n",
    "print(digits.images.shape)\n",
    "print(digits.target.shape)\n",
    "print(digits.target_names)\n",
    "\n",
    "X = digits.data\n",
    "y = digits.target\n",
    "Xtrain,Xtest = np.split(X,[1000])\n",
    "ytrain,ytest = np.split(y,[1000])\n",
    "#Xtrain = X[:1000,:]\n",
    "#ytrain = y[:1000]\n",
    "#Xtest = X[1000:,:]\n",
    "#ytest = y[1000:]\n",
    "\n",
    "#plt.gray();\n",
    "#plt.matshow(digits.images[0]);\n",
    "#plt.show();\n",
    "#plt.matshow(digits.images[15]);\n",
    "#plt.show();\n",
    "#plt.matshow(digits.images[42]);\n",
    "#plt.show();\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "def shuffle_and_split(X,y,n):\n",
    "    X0,y0 = shuffle(X,y)\n",
    "    Xtrain,Xtest = np.split(X0,[n])\n",
    "    ytrain,ytest = np.split(y0,[n])\n",
    "    return Xtrain, ytrain, Xtest, ytest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Xtrain.shape)\n",
    "print(ytrain.shape)\n",
    "digits_rf = RandomForestClassifier(n_estimators=200, criterion='entropy')\n",
    "digits_rf.fit(Xtrain,ytrain)\n",
    "prediction = digits_rf.predict(Xtest)\n",
    "#print(\"Training error:\", np.sum(np.not_equal(prediction,ytest))/len(ytest))\n",
    "print(\"Generalization error:\", np.sum(np.not_equal(prediction,ytest))/len(ytest) )\n",
    "print(\"Generalization score:\", digits_rf.score(Xtest,ytest))\n",
    "print(\"Confusion matrix:\")\n",
    "print(confusion_matrix(ytest, prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute cross-validation score\n",
    "nb_trials = 20\n",
    "score = []\n",
    "for i in range(nb_trials):\n",
    "    Xtrain, ytrain, Xtest, ytest = shuffle_and_split(X,y,1000)\n",
    "    digits_rf = RandomForestClassifier(n_estimators=200, criterion='entropy')\n",
    "    digits_rf.fit(Xtrain,ytrain)\n",
    "    score += [digits_rf.score(Xtest,ytest)]\n",
    "    print('*',end='')\n",
    "print(\" done!\")\n",
    "\n",
    "print(\"Average generalization score:\", np.mean(score))\n",
    "print(\"Standard deviation:\", np.std(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's identify the misclassified images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrain\n",
    "Xtrain = X[:1000,:]\n",
    "ytrain = y[:1000]\n",
    "Xtest = X[1000:,:]\n",
    "ytest = y[1000:]\n",
    "digits_rf = RandomForestClassifier(n_estimators=200, criterion='entropy')\n",
    "digits_rf.fit(Xtrain,ytrain);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examples\n",
    "N = 1053\n",
    "plt.gray();\n",
    "plt.matshow(digits.images[N]) \n",
    "plt.show() \n",
    "x = digits.data[N,:]\n",
    "print(\"prediction on image number\", N, \":\", digits_rf.predict([digits.data[N,:]]))\n",
    "print(\"correct label                :\", digits.target[N])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find misclassified examples\n",
    "ypredict = digits_rf.predict(Xtest)\n",
    "misclass = np.not_equal(ypredict, ytest)\n",
    "Itest = digits.images[1000:,:]\n",
    "Xmisclass = Xtest[misclass,:]\n",
    "ymisclass = ytest[misclass]\n",
    "Imisclass = Itest[misclass,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display misclassified examples\n",
    "N = 1\n",
    "plt.matshow(Imisclass[N]) \n",
    "plt.show() \n",
    "print(\"prediction on image number\", N, \":\", digits_rf.predict([Xmisclass[N,:]]))\n",
    "print(\"correct label                :\", ymisclass[N])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the important pixels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = digits_rf.feature_importances_\n",
    "std = np.std([tree.feature_importances_ for tree in digits_rf.estimators_], axis=0)\n",
    "indices = np.argsort(importances)[::-1]\n",
    "fig=plt.figure(figsize=(10,10), dpi= 80, facecolor='w', edgecolor='k')\n",
    "plt.title(\"Feature importances\")\n",
    "plt.bar(range(X.shape[1]), importances[indices], color=\"r\", yerr=std[indices], align=\"center\")\n",
    "plt.xticks(range(X.shape[1]), indices)\n",
    "plt.xlim([-1, X.shape[1]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot a image of pixel importance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances_image = importances.reshape((8,8))\n",
    "plt.imshow(importances_image);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "218px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
